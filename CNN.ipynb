{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTING THE LIBRARIES\n",
    "torchvision provide sthe necessary datasets for model creations\n",
    "\n",
    "torch imports the pytorch library. We will import the nn neural network module from torch. optim module provides the built in optimization algorithms like adam will will be used further in the code for model optimization\n",
    "\n",
    "we import the functional API which provide sthe built in functions like activations functions, relu, sigmoid,pooling an convolutional layer\n",
    "\n",
    "we import ToTensor function which will convert image data to tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch,torchvision \n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as f\n",
    "from torch.autograd import Variable\n",
    "from torchvision.transforms import ToTensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Converting Image pixels data rows into tensors**\n",
    "\n",
    "we start by transforming the image data to tensors using torchvision.transforms.compose. we get the MNIST datasets from torchvision.datasets and download the dataset to our computer.\n",
    "\n",
    "We then split the datset into training and validation sets. we ussually give 80% of the data to the training set.\n",
    "Using torch.utilis.data.random_split method we divide the whole dataset in the train_data and val_data sets.\n",
    "\n",
    "We then dowwnload the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "T=torchvision.transforms.Compose(\n",
    "[torchvision.transforms.ToTensor()]\n",
    ")\n",
    "train_data=torchvision.datasets.MNIST('mnist_data',train=True,download=True,transform=T)\n",
    "val_data=torchvision.datasets.MNIST('mnist_data',train=False,download=True,transform=T)\n",
    "test_data = torchvision.datasets.MNIST('mnist_data', train=False, download=True, transform=T)\n",
    "numb_batch = 64\n",
    "train_dl = torch.utils.data.DataLoader(train_data, batch_size = numb_batch)\n",
    "\n",
    "test_dl = torch.utils.data.DataLoader(val_data, batch_size = numb_batch, shuffle=True)\n",
    "val_dl = torch.utils.data.DataLoader(val_data, batch_size = numb_batch)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataloaders are iterators that provide the facility to iterate over the whole dataset.\n",
    "We make three dataloaders, one for test,train and validation each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <torch.utils.data.dataloader.DataLoader at 0x20fe14a7c20>,\n",
       " 'val': <torch.utils.data.dataloader.DataLoader at 0x20fe14a7a40>}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "loaders = {\n",
    "'train' : torch.utils.data.DataLoader(train_data,batch_size=100,shuffle=True,num_workers=1),\n",
    "'val': torch.utils.data.DataLoader(val_data, batch_size=100,shuffle=True, num_workers=1)\n",
    "}\n",
    "loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATING THE MODEL\n",
    "\n",
    "We will make a neural network class that inherits from the nn.Module, the base class for neural networks in pytorch. We define the first convlutional layer with 1 input channel and 32 output channels and krnel size 5.\n",
    "We define the second convolutional layer with 32 input channels and 32 output channels and kernel size 5\n",
    "We define the third convolutional layer with 32 input channels and 64 output channels and kernel size 5.\n",
    "We then declare 2 fully connected layers.The "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=5)\n",
    "        self.conv3 = nn.Conv2d(32,64, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(3*3*64, 256)#input features in a flattened format 3_3_64 and 256 output features \n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = f.relu(self.conv1(x))\n",
    "        # we apply the RELU Function to the first convolutional layer\n",
    "        x = f.relu(f.max_pool2d(self.conv2(x), 2))\n",
    "        #apply the second RELU function on the previous convolutional layer\n",
    "        x = f.dropout(x, p=0.5, training=self.training)\n",
    "        #applies dropout regularization to the output of the previous layer\n",
    "        x = f.relu(f.max_pool2d(self.conv3(x),2))\n",
    "        #applies the third convolution  to the output of previous layer followed by max pooling then applying the relu functin\n",
    "        x = f.dropout(x, p=0.5, training=self.training)\n",
    "        #applies dropout regularization to the output of the previous layer\n",
    "        x = x.view(-1,3*3*64)\n",
    "        #reshaping the output\n",
    "        x = f.relu(self.fc1(x))\n",
    "        #applying relu again\n",
    "        x = f.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return f.log_softmax(x, dim=1)\n",
    "        #apply the softmax function to the output\n",
    "        return x\n",
    "    \n",
    "net = Net()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "num_classes = 10  # 0-9 digits (assuming MNIST)\n",
    "learning_rate = 0.01\n",
    "epochs = 5\n",
    "batch_size = 64\n",
    "learning_rate = 0.01\n",
    "optimizer = optim.Adam(net.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAINING THE MODEL\n",
    "We first define a device variiable to check whether the model is trained on the CPU or GPU.\n",
    "We start training the model and appluing forward propagation and then backward propagation.and finally applying optimizing techniques from the tensor module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=576, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Use GPU if available\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_loader):\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return 100 * correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Epoch [1/5], Step [100/938], Loss: 0.7064\n",
      "Epoch [1/5], Step [200/938], Loss: 0.7079\n",
      "Epoch [1/5], Step [300/938], Loss: 0.5939\n",
      "Epoch [1/5], Step [400/938], Loss: 0.5497\n",
      "Epoch [1/5], Step [500/938], Loss: 0.4674\n",
      "Epoch [1/5], Step [600/938], Loss: 0.5960\n",
      "Epoch [1/5], Step [700/938], Loss: 0.6243\n",
      "Epoch [1/5], Step [800/938], Loss: 0.3158\n",
      "Epoch [1/5], Step [900/938], Loss: 0.2322\n",
      "Accuracy of the model on the validation images after epoch 1: 94.16 %\n",
      "Epoch [2/5], Step [100/938], Loss: 0.0425\n",
      "Epoch [2/5], Step [200/938], Loss: 0.0602\n",
      "Epoch [2/5], Step [300/938], Loss: 0.0659\n",
      "Epoch [2/5], Step [400/938], Loss: 0.2432\n",
      "Epoch [2/5], Step [500/938], Loss: 0.0385\n",
      "Epoch [2/5], Step [600/938], Loss: 0.0608\n",
      "Epoch [2/5], Step [700/938], Loss: 0.0385\n",
      "Epoch [2/5], Step [800/938], Loss: 0.0140\n",
      "Epoch [2/5], Step [900/938], Loss: 0.0540\n",
      "Accuracy of the model on the validation images after epoch 2: 96.56 %\n",
      "Epoch [3/5], Step [100/938], Loss: 0.0675\n",
      "Epoch [3/5], Step [200/938], Loss: 0.0398\n",
      "Epoch [3/5], Step [300/938], Loss: 0.0496\n",
      "Epoch [3/5], Step [400/938], Loss: 0.1986\n",
      "Epoch [3/5], Step [500/938], Loss: 0.0258\n",
      "Epoch [3/5], Step [600/938], Loss: 0.1089\n",
      "Epoch [3/5], Step [700/938], Loss: 0.0501\n",
      "Epoch [3/5], Step [800/938], Loss: 0.0781\n",
      "Epoch [3/5], Step [900/938], Loss: 0.0511\n",
      "Accuracy of the model on the validation images after epoch 3: 95.40 %\n",
      "Epoch [4/5], Step [100/938], Loss: 0.0557\n",
      "Epoch [4/5], Step [200/938], Loss: 0.1385\n",
      "Epoch [4/5], Step [300/938], Loss: 0.0357\n",
      "Epoch [4/5], Step [400/938], Loss: 0.3000\n",
      "Epoch [4/5], Step [500/938], Loss: 0.0533\n",
      "Epoch [4/5], Step [600/938], Loss: 0.1872\n",
      "Epoch [4/5], Step [700/938], Loss: 0.0871\n",
      "Epoch [4/5], Step [800/938], Loss: 0.0094\n",
      "Epoch [4/5], Step [900/938], Loss: 0.0737\n",
      "Accuracy of the model on the validation images after epoch 4: 97.42 %\n",
      "Epoch [5/5], Step [100/938], Loss: 0.0539\n",
      "Epoch [5/5], Step [200/938], Loss: 0.0112\n",
      "Epoch [5/5], Step [300/938], Loss: 0.1204\n",
      "Epoch [5/5], Step [400/938], Loss: 0.1997\n",
      "Epoch [5/5], Step [500/938], Loss: 0.0466\n",
      "Epoch [5/5], Step [600/938], Loss: 0.0570\n",
      "Epoch [5/5], Step [700/938], Loss: 0.1676\n",
      "Epoch [5/5], Step [800/938], Loss: 0.0202\n",
      "Epoch [5/5], Step [900/938], Loss: 0.0938\n",
      "Accuracy of the model on the validation images after epoch 5: 97.97 %\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Use GPU if available\n",
    "net.to(device)\n",
    "\n",
    "total_step = len(train_dl)\n",
    "print(\"Training the model...\")\n",
    "for epoch in range(epochs):\n",
    "    for i, (images, labels) in enumerate(train_dl):\n",
    "        # Move data to the chosen device (CPU or GPU)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = net(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        optimizer.zero_grad() \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print training progress\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Step [{i+1}/{total_step}], Loss: {loss.item():.4f}')\n",
    "    val_accuracy = evaluate_accuracy(val_dl)\n",
    "    print(f'Accuracy of the model on the validation images after epoch {epoch+1}: {val_accuracy:.2f} %')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TESTING DATA ON TRAINING AND VALIDATION DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the training images: 97.93333333333334\n",
      "Accuracy of the model on the testing images: 97.97\n",
      "Accuracy of the model on the validation images: 97.97\n"
     ]
    }
   ],
   "source": [
    "\n",
    "correct = 0\n",
    "trainaccuracy=evaluate_accuracy(train_dl)\n",
    "testaccuracy=evaluate_accuracy(test_dl)\n",
    "valccuracy=evaluate_accuracy(val_dl)\n",
    "print(f'Accuracy of the model on the training images: {trainaccuracy}')\n",
    "print(f'Accuracy of the model on the testing images: {testaccuracy}')\n",
    "print(f'Accuracy of the model on the validation images: {valccuracy}')\n",
    "\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
